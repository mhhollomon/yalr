# YALR Architecture Overview

## Processing chain

processing the input and generating output is done in the following stages:

- Parsing - syntactic analysis of the input grammar. The output is a parse
    tree.
- Analysis - semantic analysis of the parse tree. The output is the analysis
    tree.
- Table generation - the parse table is generated by the chosen algorithm.
- Code generation - the parse table is used to generate the output code.


## Parsing

The parsing is done with a hand coded recursive descent parser in
`lib/parser.cpp`. This makes heavy use of the cheap copy available by using
`std::string_view`. The definition of the output tree is in
`include/parser_tree.hpp`.

The parse tree is a simple list of statements where each statement type is
represented by a class that is a part of a variant. This make using a visitor
pattern to walk the list easy. Most of the data in the `parse_tree` is held as
`text_fragment` so that the location information is also available.

## Analysis

Analysis happens in two passes. Each pass is implemented as a visitor over the
list of statements in the parse tree.

### Pass 1 - Gather rule symbols

Rules must be allowed to reference rules that are not (yet) defined. Pass 1
visits only those statement types that might define a rule - rule statements
and termset statements. For each such statement, it figures out the name of the
rule and adds it to the symbol statement.

Along the way, it keeps track of the goal rule and checks that there are not
two rules so marked. It also checks that there are not two rules with the same
name.

Note that terms and skips are **not** handled. This is so that all terms
**must** be defined before use (or defined inline as quoted patterns).

However, this may lead to odd error messages. consider the following fragment.

```
term X 'x' ;
rule X { => 'x' ; }
```

Because pass 1 registers X as a rule (but does not consider the term), when
pass 2 **does** consider the term, it will mark it a duplicate - a bit counter
intuitive to the user.

### Pass 2 - Heavy Lifting

This is where most of the actual analysis is done.

Symbols used in rules are linked to the actual symobl definition in the symbol
table. Anything missing is flagged. Rule alteratives are broken into individual
productions for the table generator. Inline terminals are enrolled. Precendence
and associativty is parsed and checked for validity. Termsets are exploded into
the corresponding rule and terminals.

## Table Generation

Table generation is done by one of the subclasses of `parser_generator`. The
shape of the output is considered opaque - for the use of the class alone. The
only thing passed back up to the driver is a success flag and any generated
errors/warnings.

Current generator list :
- SLR - SLR(1) parser generator based on a fairly naive implementation of the
    algorithm from the "Dragon Book".

## Code Generation

Also done by subclasses of `parser_generator`. The SLR generator uses
[inja](https://github.com/pantor/inja) template engine to generate the code.
